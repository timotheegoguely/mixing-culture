## II. I/O Creative Process

Lorsque nous allons sur le web, nous passons alternativement, et presque s’en nous en rendre compte, d’une position de récepteur à celle d’émetteur. Si cela peut paraître évident aujourd’hui, ce n’était pas le cas il y a encore un vingtaine d’années à l’ère du web 1.0 : internet était alors constitué de pages liées entre elles par des hyperliens, et était utilisé la plupart du temps comme un simple moyen de recherche et de consultation d’informations. Seule une très faible partie d’usagers possédant les compétences techniques nécessaires était en mesure d’y ajouter du contenu.
Cela devint de plus en plus simple à partir du début des années 2000, grâce notamment au développement des interfaces et des principes d’interactivité. Le passage au web 2.0 permit ainsi à chacun, de façon individuelle ou collective, de contribuer, d’échanger et de collaborer de façon active – d’où son surnom de web social.
Nous sommes à présent dans l’ère de ce que Tim Berners-Lee – qui n’est autre que l’inventeur du World Wide Web et le fondateur du World Wide Web Consortium (W3C) – appelle le web sémantique.[^92] Celui-ci ‹ vise à aider l’émergence de nouvelles connaissances en s’appuyant sur les connaissances déjà présentes sur Internet. Pour y parvenir, le web sémantique met en œuvre le web des données qui consiste à lier et structurer l’information sur Internet pour accéder simplement à la connaissance qu’elle contient déjà. ›[^93]
À terme [schéma], le web se dirigerait vers un métaweb, parfois appelé web “omniscient”, sorte de réseau d’intelligences connectées alliant à la fois les qualités du web social et celles du web sémantique.


Mais revenons-en à notre sujet. Nous disions donc que de nos jours, sur le web, nous passons systématiquement d’une position de récepteur à celle d’émetteur, et inversement. Effectuons ici la comparaison avec ce que l’on appelle dans un système d’exploitation les “entrées-sorties” (Input/Output en anglais, ou I/O). Ce terme désigne les échanges d’informations entre le processeur et les périphériques qui lui sont associés. Les entrées désignent alors les données envoyées par un périphérique (disque, réseau, clavier…) à destination de l’unité centrale, tandis que les sorties désignent les données émises par l’unité centrale à destination d’un périphérique.[^94]
Ne sommes-nous pas nous-mêmes en quelque sorte ce “système d’exploitation”, sans cesse recevant et émettant des données, en provenance et à destination de multiples sources ?


À partir de cette analogie, nous allons ainsi tenter d’analyser le processus créatif lié à la pratique du mix en le décomposant en deux grandes temporalités : une première, que nous appellerons donc input, correspondant aux étapes de recherche, d’organisation et de sélection de contenu, et une seconde, output, regroupant les étapes de conception, de monstration et d’archivage du projet résultant de l’assemblage de ce contenu.
J’insiste sur le fait qu’il ne s’agit pas là d’une “recette”. Cette décomposition en étapes selon un ordre chronologique à été pensée pour permettre de mieux distinguer leurs enjeux respectifs, mais dans la réalité, cet ordre n’est pas nécessairement respecté : le “praticien du mix” passera souvent d’une étape à une autre, selon le projet sur lequel il travaille et selon son propre workflow. 


### A. Input

#### 1. Chercher, collecter
Selon ce découpage qui sera le notre tout au long de ce chapitre, la première étape correspond au temps de recherche et de collecte du contenu qui constituera la matière première de notre projet. Se pose alors immédiatement la question des sources. Si les livres, bibliothèques et autres moyens “traditionnels” de consultation restent des sources d’information tout à fait valables, nous nous attarderons cependant ici davantage sur le web, pour la simple et bonne raison qu’il correspond aujourd’hui au moyen de recherche le plus commun et le plus complet, et qu’en plus de cela, il permet l’accès à ces mêmes livres et bibliothèques – du moins à leurs références, lorsque ce n’est pas directement à leur contenu sous forme numérique.

En effet, de nos jours, une grande partie du contenu culturel consommable mondial (films, musique, livres, jeux vidéos, émissions de radio et de télévision) est accessible dans son intégralité sur le web, que se soit de manière légale ou illégale, gratuite ou payante – légal n’étant d’ailleurs pas forcément synonyme de payant et illégal de gratuit.
Ainsi, pour trouver tel ou tel contenu sur le web, le premier réflexe que nous avons tous aujourd’hui est d’effectuer une requête sur Google – même si d’autres moteurs de recherche existent (Yahoo, Yandex, Bing, ou encore Baidu en Chine, pour citer les principaux), le monopole exercé par Google est tel que “googler” est désormais synonyme dans le langage courant de “chercher sur internet”.
Si, avec le développement de l’analyse sémantique par les moteurs de recherche, il est désormais possible de poser une question en langage naturel, la principale méthode reste celle consistant à procéder par addition (et soustraction pour les plus pointilleux d’entre nous) de mot-clés, en en regroupant éventuellement certains entre guillemets pour qu’ils constituent une seule et même unité de recherche. Le fait d’effectuer une recherche en anglais, plutôt qu’en français, permet également d’élargir considérablement le champ de recherche, et donc les chances de tomber sur un contenu pertinent.
Cette méthode de recherche – que chacun d’entre nous maîtrise plus ou moins – est directement liée au fonctionnement des moteurs de recherche, et n’en constitue que la partie visible et accessible au travers d’une interface. En effet, les moteurs de recherche, comme tout outil de recherche, fonctionnent selon un processus pouvant être découpé en trois temps principaux : l’exploration, l’indexation et la recherche.[^95] Ce triple processus entièrement automatisé par des robots (bots) se base essentiellement, en amont, sur l’analyse algorithmique de la fréquence de certains termes significatifs au sein d’une page web (les termes non significatifs tels que “la”, “le”, “de”, “du”, etc. étant appelés mots vides) afin de leur attribuer un poids.[^96] Celui-ci servira en aval, selon le processus inverse, à classer les résultats d’une requête par ordre décroissant de pertinence sous forme de pages.[^97]

Si les moteurs de recherche sont parfaits pour (re)trouver une information précise de type factuel (nom, titre, date, etc.), la plupart des contenus intéressants sur lesquels nous “tombons” sur internet n’est pas directement le résultat d’une recherche à proprement parler. C’est ce que l’on appelle la sérendipité. Comme en témoigne la page Wikipédia à ce sujet, la définition de ce concept, devenu très à la mode ces dernières années, suscite de nombreux débats, chacun y allant de sa petite interprétation en fonction du domaine professionnel dont il est issu.[^98] Les spécialistes semblent tout de même s’accorder sur l’origine historique du terme.
Il s’agit d’un néologisme créé en 1754 en Angleterre par Horace Walpole (1717–1797) en référence au conte perse Voyages et aventures des trois princes de Serendip (le Sri Lanka d’alors), qu’il avait lu enfant dans la version de Louis de Mailly, et dans lequel les héros, tels des chasseurs, utilisent des indices pour décrire un animal qu’ils n’ont pas vu. Walpole décide alors d’employer le terme de serendipity pour désigner des ‹ découvertes inattendues, faites par accidents et sagacité ›.
Le sens de ce terme évoluera par la suite de nombreuses fois en passant entre les mains de différentes sphères d’activités (littérature, science, publicité, sciences humaines, économie), jusqu’aux années 2000 où il sera repris par les usagers du web 2.0 pour désigner “l’art de trouver ce que l’on ne cherche pas”. Francisé depuis, nous parlerons donc de sérendipité en référence au fait de trouver par hasard sur le web des contenus qui nous intéressent.
Mais peut-on vraiment parler de “hasard” lorsque nous naviguons sur le web ? En considérant que toute page que nous consultons est le résultat d’une action intentionnelle (il faut bien cliquer sur tel ou tel hyperlien pour accéder à son contenu), il serait plus juste de parler d’une succession de micro-décisions. Cependant, la structure des pages web est telle que nous avons sans cesse sous les yeux plus de contenus et d’informations que ce que nous souhaitions initialement consulter : une requête sur Google ne propose jamais – et heureusement ! – qu’un seul résultat, des publicités plus ou moins ciblées se présentent constamment à nous sans que nous l’ayons décidé, une vidéo est systématiquement accompagnée de suggestions d’autres vidéos à visionner, à la fin d’un article sont souvent proposés d’autres articles se rapprochant du sujet abordé, etc. Cela peut paraître évident, mais il faut bien se rendre compte que ces principes d’architecture du web ont été pensés par des ingénieurs, des programmeurs et des designers, et que le concept de sérendipité et donc implicitement induit par la nature même du web.
Ainsi, comme le souligne Jean-Marie Durand dans un article de 2011 paru sur le site du magazine Les Inrocks, ‹ mieux qu’un concept, [la sérendipité] désigne une méthode de recherche, une attitude créative propre à la culture du web. ›[^99] C’est une sorte d’errance féconde liée à une certaine disposition d’esprit, une curiosité à la fois instinctive et réceptive. Durand conclut son article en établissant un parallèle entre le concept de sérendipité et celui d’abduction :

‹ Quête active, même si elle n’a pas de but connu, contraire d’une attente passive, la sérendipité correspond à une procédure logique peu classique : “l’abduction”, par opposition à l’induction, qui repose sur la causalité, […] et à la déduction […] Du côté de l’abduction, il n’existe plus de point de départ ni d’arrivée : on construit des hypothèses à partir d’un ensemble donné de faits qui ne leur sont a priori reliés en rien. ›[^100]

Pour éviter de nous perdre face aux méandres du web, les sites communautaires de partage de contenus ont progressivement intégré des systèmes de référencement de l’information basés essentiellement sur le principe de mot-clé, principe que nous évoquions plus haut à propos des requêtes effectuées sur les moteurs de recherche.
Démocratisé par les plates-formes d’édition de blog, ce système de tag (ou en français étiquette, marqueur, libellé), permet ainsi d’associer un ou plusieurs mots-clés relatifs à un contenu (image, article, vidéo, etc.) afin de regrouper facilement les contenus contenant les mêmes mots-clés au sein d’une même catégorie. On le retrouve désormais sous une forme dérivée appelée hashtag. Précédé par le symbole #, tout hashtag est automatiquement transformé en hyperlien, pouvant ainsi devenir un élément requêtable au sein de telle ou telle plate-forme – Twitter bien sur, mais aussi Facebook, Tumblr, Pinterest ou encore Instagram, qui ont tous adopté ce système aujourd’hui – afin notamment d’identifier les hashtags les plus populaires du moment sous forme de liste mise à jour en temps réel (trending hashtags).

Les (hash)tags étant choisis de façon personnelle par l’internaute, dépassent ainsi toute catégorisation a priori selon des schémas de classification prédéfinis. On parle alors de “folksonomie”. Appelée aussi “indexation personnelle”, la folksonomie désigne ‹ un système de classification collaborative, décentralisée et spontanée, basé sur une indexation effectuée par des non-spécialistes. ›[^101] Inventé par l’architecte de l'information Thomas Vander Wal et francisé depuis, ce mot-valise combinant les mots folk (le peuple, les gens) et taxonomy (la taxinomie) s’oppose ainsi aux systèmes de classification traditionnels, standardisés, rigoureux et pensés par des professionnels, tels que la classification décimale universelle ou la classification Dewey. Ce phénomène de masse, en usage depuis 2004 et désormais démocratisé, répond aux besoins grandissant de référencement du contenu présent sur le web qui ne cesse de croître, et permet par là même à l’internaute de naviguer de manière intuitive, transversale et horizontale au sein de celui-ci. [exemple tags SoundCloud]
On retrouve également ce système de tagging sur la plupart des logiciels de notes et d’archivage de contenu tels que Pocket ou Evernote [image], ainsi que sur les plates-formes de social bookmarking (“partage de signets” en français) telles que Delicious, Digg, Reddit ou encore Stumbleupon [images].

L’ensemble de ses usages contemporains du web, utilisés dans une optique de recherche, permettent ainsi à quiconque de collecter un maximum d’informations et de contenus autour du sujet de son choix. Se pose alors une nouvelle question, celle du stockage de ces ressources. Car pour constituer un véritable matériau de travail, dans le sens de matière première numérique, il faut bien “posséder” à un moment donné certaines de ces ressources sous forme de fichiers sur un disque dur. Différentes pratiques font alors leur entrée en jeu : téléchargement, capture d’écran, copier-coller.
Au travers de ce passage d’un contenu “en ligne” (online) à un contenu “hors ligne” (offline), de cet acte d’appropriation typique du numérique, s’opère le passage du consommateur passif au consommateur actif. Car à l’heure de Pinterest et du streaming généralisé, posséder une image ou un morceau de musique sur son ordinateur, c’est déjà affirmer une certaine attitude à son égard : au-delà de la prise d’indépendance vis-à-vis du fait d’être connecté à internet pour y accéder, il devient potentiellement duplicable et modifiable à l’infini, c’est-à-dire exploitable à des fins créatives.

#### 2. Organiser, classer
La seconde étape du processus consiste à organiser le résultat de nos recherches. Et là encore, le numérique et le web ont permis l’émergence de nouvelles pratiques en la matière. 

Le besoin d’ordonner les choses qui nous entourent au quotidien varie selon les individus en fonction de leur caractère, de leurs habitudes et de leur style de vie. L’un des exemples les plus révélateurs à ce sujet consiste à observer le bureau d’une personne. Enfin, je devrais dire “les” bureaux, car qu’il s’agisse de notre table de travail[^102] ou de notre bureau informatique, chacun d’eux en dit long sur notre personne. “Montre-moi ton bureau, je te dirai qui tu es”. Alternant entre phases de dénuement minimaliste et de saturation “bordélique”, la plupart d’entre nous procède selon un système de classement plus ou moins personnel que nous nous efforçons tant bien que mal de respecter. J’insiste sur le “plus ou moins personnel”, car nos ordinateurs – plus que nos bureaux “physiques” – possèdent tous un système de classement prédéfinit.

[screenshot dossier “documents, images, sites, téléchargement”, etc.]

Ce système arborescent par défaut, qui dépend du système d’exploitation installé, nous induit inconsciemment à suivre un certain mode d’organisation de nos fichiers et de dossiers, c’est-à-dire un certain mode de pensée.

Car classer, pour paraphraser Georges Perec,[^103] c’est déjà d’une certaine façon penser. Dans un article à ce sujet, Gérard Régimbaud nous rappelle que, dans son livre Les mots et les choses,[^104]‹ Michel Foucault s’arrête tout un chapitre sur l’acte de « Classer ». La classification y est définie dans ces développements comme la conséquence d’un paradigme dans l’histoire de la pensée, celui de la « mise en visibilité ». ›[^105] Mais que rendons-nous visible au juste en classant ? Pour pouvoir répondre à cette question, il nous faut déjà décortiquer l’acte de classification. En effet, ce terme renferme différentes notions, actions et opérations mentales qu’il nous faut distinguer.

Commençons par le tri. L’action de trier désigne en son sens premier l’action de ‹ séparer ce que l’on souhaite garder et ce que l’on souhaite jeter. ›[^106] C’est ce que nous faisons par exemple lorsque nous trions nos photos ou nos musiques sur notre ordinateur : nous en supprimons certaines pour ne conserver que celles “de qualité” en fonction d’un contexte déterminé et selon notre jugement.

Passons ensuite à la catégorisation. Cette activité mentale ‹ consiste à placer un ensemble d’objets dans différentes catégories en fonction de leurs similarités ou de critères communs. ›[^107] Selon Richard Ladwein (professeur à l’université de Lille en marketing et communication), ‹ d’une manière générale la fonction de l’organisation catégorielle des connaissances est de réduire la complexité de l’environnement, et de le structurer en un nombre restreint de termes mémorisables et opérants. ›[^108] Le processus cognitif de la catégorisation est donc directement lié à la mémoire, dans le sens où le fait d’attribuer une catégorie à quelque chose, en nous aidant ainsi à l’identifier, permet de nous en rappeler plus facilement.
Depuis la version 10.9 du système d’exploitation d’Apple, une nouvelle fonction de tag a fait son apparition, permettant à l’utilisateur de catégoriser (taguer) ses fichiers et dossiers selon son propre système (voir image). L’idée étant bien sûr de pouvoir ensuite effectuer une recherche par tag au sein de son disque dur. On voit bien comment les systèmes de classification nés sur le net et dont nous parlions dans la partie précédente, se retrouvent désormais sur nos ordinateurs et modifient notre rapport à leur contenu.

Un autre aspect découlant de la classification est l’action d’ordonner. Il s’agit là d’attribuer un certain ordre à une liste d’objets selon une logique déterminée. Prenons par exemple plusieurs crayons de couleurs. Il est possible de les ordonner aussi bien par couleurs (suite chromatique, chaud/froid, goût personnel, etc.) que par taille (croissante ou décroissante, qui dans ce cas là équivaudra à leur fréquence d’utilisation). Autre exemple, sur Mac OS encore, l’affichage en mode colonne propose ainsi différentes logiques : par nom (ordre alphabétique), par type (format), par date de dernière ouverture, d’ajout, de modification, de création (ordre chronologique décroissant), et par taille (du plus lourd au plus léger). [image]
Si cette action pourrait ne pas sembler essentielle au premier abord, elle peut cependant permettre “d’y voir plus clair” au sein d’un groupe d’éléments et surtout de repérer certaines logiques internes, des motifs récurrents (patterns), qui peuvent devenir le point de départ d’un projet.

Les possibilités offertes par l’ensemble de ces pratiques de classement se trouvent décuplées grâce à l’intégration au sein même des fichiers de toujours plus de métadonnées. Directement issu des systèmes de classement sous forme de fiches cartonnées, employées jadis au sein des bibliothèques et autres archives, l’usage des “métadonnée” (metadata en anglais, littéralement “données à propos de données” – le prefixe grec meta indiquant l’auto-référence) s’est démocratisé à partir des années 90 dans le cadre de la description des ressources sur Internet. Différentes normes et standards ont ainsi vu le jour et continuent de se développer, couvrant toujours plus de champs et permettant une précision toujours plus importante.
Citons à titre d’exemple la norme XMP (Extensible Metadata Plateform) développée par Adobe,[^109] s’appliquant à des fichiers textes, des images et autres types de média et permettant d’attribuer des informations aussi précises que le code postal et l’adresse mail du créateur, le lieu où a été prise une photographie, ou encore les informations relatives aux droits d’utilisation du fichier. [voir image Bridge] 
Du côté des fichiers audio MP3, le standard ID3 inventé par Eric Kamp en 1996 permet de leur attribuer le titre du morceau, le nom de l’artiste, de l’album, son année de sortie, son genre musical, mais aussi, depuis la version 2.4 sortie en l’an 2000, tout un tas d’autres métadonnées telles que la pochette de l’album, le label, les paroles, le nom du compositeur et j’en passe.[^110]
La plupart de ces métadonnées peuvent être récupérées, lues et éditées à l’aide de logiciels de gestion de ressources numériques tels qu’Adobe Bridge ou iTunes, qui permettront à leur tour différentes options de regroupement par filtre en fonction de ces métadonnées. On pourra alors ordonner par exemple une liste de morceaux en fonction de leur tempo (BPM : beat per pinute) ou de leur pays d’origine, créant ainsi des rapprochement entre des morceaux auxquels nous n’aurions pas forcément pensé spontanément.

On passe alors du statut de consommateur actif à celui d’amateur-collectionneur. Au travers de l’organisation de sa collection, combinant systèmes de classifications objectifs (métadonnées) et subjectifs (tags, dossiers), des ensembles émergent naturellement, des liens commencent à s’établir d’eux-mêmes.
Cependant, si ceux-ci peuvent parfois donner des idées de projets,[^111] l’étape d’éditorialisation qui suit reste indispensable à l’affirmation d’un point de vue singulier et d’un parti pris en tant que créateur.
 
#### 3. Sélectionner, choisir
Une fois notre contenu collecté convenablement classé et organisé, vient donc le temps de la sélection. Sélectionner, c’est choisir au sein d’un ensemble, ce qui répond le mieux à un ou plusieurs critères donnés. Le terme editing en anglais – terme qui n’a pas vraiment d’équivalent en français[^112]– englobe cette action, en lui ajoutant l’idée de préparation des contenus ainsi sélectionnés. En voilà une définition complète :
‹ L’editing est le processus de sélection et de préparation de contenus écrits, visuels, sonores et filmiques utilisés pour transmettre des informations. Le processus d’editing peut impliquer la correction, la condensation, l’organisation, et d’autres modifications effectuées avec l’intention de produire un travail correct, cohérent, précis et complet. ›[^113] On retrouve cette expression couramment dans les domaines de l’édition (textes /images) et de la photographie (images). [photo editing maison d’édition]

La sélection de contenus sous-tend nécessairement une intention de départ chez son auteur. En effet, le “simple” fait de sélectionner du contenu peut constituer le cœur de nombre de projets éditoriaux. Je pense notamment ici aux compilations musicales, cette forme particulière d’album contenant plusieurs titres de différents interprètes, ou bien rassemblant plusieurs morceaux d’un même artiste enregistrés à l’origine sur différents disques. Le parallèle avec la sélection des artistes et des œuvres pour une exposition est flagrant : certes, les formes finales ont peu en commun, mais une partie des enjeux (rendre compte, faire revivre, laisser une trace) et les types de regroupements les plus courants (style, mouvement, origine géographique, période) sont très proches.

Le principe de la compilation s’est aujourd’hui largement démocratisé sous sa forme populaire que constitue la playlist. Une playlist (littéralement “liste de lecture”) désigne ‹ un ensemble de morceaux musicaux ou de fichiers audio/vidéo compilés dans un agrégateur. Ils peuvent être joués séquentiellement, dans un ordre aléatoire [shuffle] ou selon une logique choisie par celui qui l’a composée. ›[^114] Désormais, toutes les plates-formes de lecture/partage de musique et de vidéo telles que YouTube, Vimeo, rdio, Grooveshark, Spotify ou Deezer proposent à leurs utilisateurs de créer des playlists pour regrouper des contenus autour d’une thématique de leur choix. Si cette fonction est la plupart du temps utilisée comme simple marque-page ou pour constituer des best-of, elle offre néanmoins une infinité de possibilités narratives trop peu souvent exploitées.
Et comme le rappelle très justement Jean-Yves Leloup, ‹ la culture des médias et du DJing est passée par là […] Le terme de “playslist” a d’ailleurs son origine dans les années 1940 et la grande époque de la radio américaine où ce terme désignait la liste de titres joués en priorité sur les stations. ›[^115]

Lorsqu’une playlist est partagée sur le web, c’est-à-dire rendue publique et accessible à tous, le processus cesse alors et la sélection devient une fin en soi. Notre amateur-collectionneur devient alors en quelque sorte curateur-prescripteur, dans le sens où il propose aux yeux et aux oreilles du monde une vision personnelle et intime de “sa” culture.
À l’inverse, lorsque la sélection reste dans le cadre privé et ne constitue seulement qu’une étape du processus créatif, notre amateur-collectionneur endosse alors un rôle plus proche de celui de l’editor, au sens anglo-saxon du terme désignant la personne en charge de l’editing. Et là encore, comme le souligne Lev Manovich, la figure du DJ nous apporte un éclairage des plus intéressants pour cerner les enjeux de cette étape que constitue la sélection :


‹ C’est le DJ qui démontre le mieux la nouvelle logique de la sélection et de la combinaison d’éléments préexistants, ainsi que le véritable potentiel de cette logique pour la création de formes artistiques nouvelles. Mais le DJ prouve également que la sélection ne suffit pas en soi. L’essence de son art réside dans sa capacité à mixer les éléments choisis de manière riche et sophistiquée. Contrairement à la métaphore moderne de l’interface homme/machine “copier-coller”, qui laisse penser qu’il suffirait de combiner simplement, presque mécaniquement des éléments sélectionnés, la pratique de la musique électronique produite en direct démontre que l’art véritable, c’est le mix. ›[^116]

### B. Output
Une fois le contenu collecté, organisé et sélectionné, il s’agit à présent de lui donner une forme, de la présenter, et d’en garder une trace. Nous allons donc tenter d’analyser dans cette seconde partie, ces trois étapes qui constituent la phase d’output, c’est-à-dire le temps au sein duquel, à partir d’éléments préexistants, émerge le projet à proprement parler, sous une forme singulière qui sera soumise à l’appréciation d’un public extérieur.

#### 4. Assembler, monter
Ici commence donc le véritable travail de mix. Même si nous reviendrons plus en détails sur cette notion de “mix” dans le troisième chapitre de cette étude, nous allons d’ores et déjà nous pencher sur son potentiel créatif et narratif en tant que mode d’expression à part entière, et sur certaines des notions et des mécaniques internes qui en découlent.
Pour ce faire, nous allons mettre en parallèle différentes théories et techniques de “montage” issues du DJing, du cinéma, de la bande dessinée ainsi que de la communication graphique, afin d’en discerner les facteurs communs et ainsi tenter d’en comprendre l’essence.

Revenons-en donc de nouveau à la pratique de notre fameux DJ. Traditionnellement, le setup (la configuration) basique d’un DJ se compose de trois éléments principaux : deux platines reliées à un mixeur. Ce dernier, en plus d’être connecté à une ou plusieurs sorties audio (enceintes et/ou casque) permettant ainsi l’écoute et la pré-écoute du résultat, offre la possibilité de passer d’une source audio (platine A) à une autre (platine B) grâce au crossfader. Il permet également entre autre de régler individuellement le volume de chaque entrée et sorties audio, d’égaliser[^117] le signal audio des différentes sources, ainsi que d’appliquer divers filtres et effets sonores. [image DJ setup]
En somme, ce setup minimal n’offre ni plus ni moins que différents types d’enchaînement et de combinaisons entre deux éléments (ou plus, en fonction du nombre de sources) selon les deux modes opératoires suivants :
– transition : A › B, B › A
– addition : A + B
L’histoire du DJing moderne témoigne de l’imagination et de la maîtrise technique toujours plus grande dont ont fait preuve les DJ, au travers notamment de la pratique du turnablism,[^118] pour sans cesse repousser les limites de ces deux principes de base.

Mais selon moi, à son niveau le plus primaire, la pratique du mix telle que l’exerce le DJ se rapproche en de nombreux points de celle du montage cinématographique. En effet, il s’agit dans les deux cas de produire des séquences par succession d’unités cohérentes (morceaux / plans) qui constitueront au final une œuvre qui possédera à son tour une cohérence d’ensemble, à la fois narrative et stylistique. Si les processus divergent – supports différents obligent – certaines théories concernant le montage cinématographique nous éclairent sur les mécaniques intrinsèques de tout mix, voir de tout “montage” au sens large.

Parmi ces théories, l’une des plus instructives est le biais cognitif appelé “effet Koulechov”, du nom de son son théoricien Lev Koulechov. Ce réalisateur russe réalisa en 1921 une expérience fascinante et novatrice : il choisit un gros-plan de l’acteur vedette de l’époque Ivan Mosjoukine, gros-plan sur lequel le visage de l’acteur est neutre et ne laisse paraître aucun sentiment particulier. Il déclina ce plan à l’identique trois fois. La première fois, il le fit suivre de l’image d’une assiette de soupe. La deuxième fois, il inséra le plan d’un cercueil dans lequel reposait un enfant. Et enfin, celui d’une femme lascive allongée sur un canapé. Interrogés après le visionnage de chaque séquence, les spectateurs devaient caractériser le sentiment exprimé par l’acteur. Dans le premier cas, les spectateurs crurent percevoir la faim, dans le second la tristesse, et dans le dernier le désir.
L’effet K, ou encore “expérience Mosjoukine”, désigne ainsi ‹ la propension d’une image à influer sur le sens des images qui l’entourent dans un montage cinématographique. Ainsi, les images ne prennent sens que les unes par rapport aux autres, et le spectateur est amené inconsciemment à les interpréter dans leur succession et non de façon indépendante. ›[^119]
Dans un article publié à ce sujet sur le site pour cinéphiles Grand Écart, Jean-Nicolas Berniche fait le parallèle avec une autre expérience menée par Chris Marker sous le nom de Lettre de Sibérie, dans le prolongement de celle Koulechov réalisée au temps du cinéma muet :

‹ [Chris Marker] y explique – entre autres choses – la force du montage sonore en appliquant aux mêmes images trois textes différents : le premier fait l’éloge de l’URSS, le deuxième la critique abondamment, et le troisième choisit l’objectivité. Force est de constater que les trois voix off chevauchent parfaitement les images, les rendant tour à tour séduisantes ou terrifiantes. Contrairement à l’idée reçue, Marker précise que l’objectivité ne permet pas non plus d’appréhender la réalité sibérienne, elle constitue d’ailleurs en l’espèce le commentaire le plus injuste. « On fait dire aux images ce qu’on veut. » Une formule toute prête dont la démonstration, ici éclatante, relativise grandement le travail du comédien comme celui du metteur en scène. Sir Alfred Hitchcock ne s’y était pas trompé, en affirmant que le montage est l’élément clé de la grammaire cinématographique. ›[^120]

L’effet K constitue donc le fondement de la narration cinématographique, mais il peut également s’appliquer par analogie à la narration visuelle dans son ensemble, et tout particulièrement à la bande dessinée. Comme l’explique en détails Scott McCloud dans le troisième chapitre de son célèbre ouvrage L’Art Invisible consacré à l’étude du 9e art, la grammaire de la bande dessinée est entièrement basée sur la notion d’ellipse. L’ellipse serait donc à la bande dessinée ce que le montage est au cinéma.
McCloud identifie ainsi 6 types d’enchaînement entre deux cases – il précise bien qu’il ne s’agit là que d’un instrument d’analyse et non d’une science exacte – correspondant au 6 types d’ellipses propres à la bande dessinée[^121] :

1. De moment à moment : fait très peu appel à l’ellipse ;
2. D’action à action : on voit un personnage au cours d’une action en train de se dérouler ;
3. De sujet à sujet : changement de focalisation à l’intérieur d’un même thème ;
4. De scène à scène : les cases ont des contenus très éloignés dans l’espace et dans le temps ;
5. De point de vu à point de vue : la notion du temps qui passe est en grande partie évacuée, le regard se promène sur différents aspects d’un endroit, d’une idée, d’une atmosphère ;
6. Solution de continuité : deux cases sont juxtaposées sans aucun rapport logique entre elles.

Ainsi, plus on avance dans cette suite, plus l’effort de déduction que doit fournir le lecteur pour établir le rapport entre les cases est important, et plus les liens spatio-temporels entre celles-ci tendent à disparaître. McCloud s’arrête un instant sur la sixième catégorie :

‹ Peut-il y avoir une suite de cases qui n’entretiendraient entre elles aucun rapport ? Personnellement je ne pense pas. Aussi différentes que deux cases puissent être, il y a toujours une sorte d’alchimie qui opère dans l’espace qui les sépare, et qui nous fera trouver un sens au rapprochement le plus discordant. De telles juxtapositions ne véhiculent pas un sens de façon traditionnelle, mais une signification finit toujours par se dégager. Quand nous créons deux ou trois images qui se suivent, nous les dotons de ce fait d’une identité intrinsèque, et forçons le lecteur à les considérer comme un ensemble. Aussi distinctes qu’elles aient pu être, elles constituent maintenant un seul organisme. L’ellipse pour le sang, les caniveaux [l’espace entre les cases], pour les veines… ›[^122]

Ces différentes mécaniques narratives liées à la juxtaposition de deux images, Chip Kidd (designer graphique et écrivain new-yorkais né en 1964) les a parfaitement comprises et mises en pratique au travers des nombreuses couvertures de livres qui lui valurent sa renommée internationale.

[images covers Chip Kidd]

Par ses jeux de confrontations et de cadrages, Chip Kidd fait émerger un sens nouveau dépassant celui des deux images originelles, selon le principe du 1+1=3 développé par l’écrivain français Bernard Werber : ‹ l’addition de deux éléments donne une somme plus importante que leur simple juxtaposition. ›[^123]

Appliquée à l’audiovisuel, cette métaphore philosophique – évidemment fausse mathématiquement – rejoint les théories de Koulechov et de McCloud. Ainsi, deux éléments (images ou sons) mis l’un à la suite de l’autre – que ce soit dans l’espace (BD, communication graphique) ou dans le temps (cinéma, musique) – génèrent automatiquement dans l’esprit du spectateur/auditeur une idée tierce qui transcende leur sens premier. Avec ce principe en tête, il est possible de créer des jeux de confrontations des plus intéressants en exploitant par exemple l’espace de la double page d’un livre, le recto et le verso d’un support, ou de manière générale, toute forme de division et de séquençage d’un espace au sens large (visuel ou sonore). Les possibilités sont infinies.

Cela dit, la juxtaposition “brute” de deux éléments n’est qu’une forme de transition parmi tant d’autres. Nous parlerons ici de “transition” en sens de raccord (cut), c’est à dire pour désigner le passage d’un élément à une autre. Et nous emploierons le terme “élément” pour désigner indifféremment un plan (cinéma) ou un morceau (DJing).
Nous pouvons déjà noter que le terme “cut” est aussi bien employé en cinéma qu’en DJing, pour désigner une transition abrupte d’un élément à une autre. Il existe dans de ces deux domaines tout un panel de cuts pouvant être utilisés pour produire certains effets esthétiques et narratifs. Sans rentrer dans les détails – je renvoie ici le lecteur souhaitant approfondir ces techniques à quelques références en ligne[^124] – effectuons brièvement l’analogie entre deux de ces principes de transitions : le fondu et le match.
En musique comme en cinéma, un “fondu” (fade ou dissolve en anglais) désigne le fait de passer plus ou moins lentement et de manière progressive d’un élément à une autre. Entre deux éléments, on parle alors de “fondu-enchaîné”.[^125] Au sein de l’œuvre d’Orson Welles, Jean Douchet (cinéaste français également historien, critique, écrivain et enseignant) décrit l’usage de cet effet comme une lutte entre deux images basée sur l'idée de rémanence – phénomène sur lequel est fondé le cinéma – marquant le conflit entre ce qui vient (« l’action ») et ce qui s’en va (« la contemplation ») :

‹ L’image qui naît l’emporte sur l'image 1 qui se meurt, mais celle-ci n’en finit pas de disparaître si bien qu’on ne sait plus si la 2 est victorieuse ou si au contraire elle n’est pas impressionnée (surimpressionnée) par la 1 qui la marque et la détruit complètement. ›[^126] 

En DJing, on appelle ce type de transition effectuée à l’aide du crossfader – que nous évoquions tout à l’heure en introduction – un cross-fade. Pour fonctionner, celui-ci est alors quasi systématiquement couplé au principe de beatmatching, procédé inventé, comme dans l’avons vu dans le premier chapitre, par Francis Grasso, et selon lequel deux morceaux sont rythmiquement “calés”, c’est-à-dire que leur tempo respectif a été synchronisé à l’aide du régulateur de vitesse (pitch).
On retrouve en cinéma ce principe de match, que l’on pourrait traduire par “correspondance” en français, pour décrire des transitions établissant une forte connexion entre deux plans. Cette connexion peut être soit purement visuelle et esthétique (match cut, ou graphic cut), soit basée sur l’action (match on action), soit entre le regard d’un personnage et l’objet de son regard (eyeline match). D’un point de vu narratif, ce type de transition permet de relier thématiquement et métaphoriquement deux éléments.

[images Kubrick, 2001: l’Odysée de l’espace + Eyeline match Dario Argento, The Stendhal Syndrome (La Sindrome di Stendhal), Italie, 1996]

Depuis les années 90, le montage “direct” – aussi appelé non-linéaire, en opposition au montage linéaire photochimique – permet d’assembler de façon non-destructive des éléments à l’aide des principes de “drag and drop” (glisser/déposer) et de “copier/couper-coller” typiques au numérique, bien qu’issus des pratiques analogiques.
On retrouve désormais cette même souplesse d’usage en terme de manipulation de contenu dans l’ensemble des domaines de création “assistés par ordinateur” grâce aux logiciels toujours plus performants d’édition, de composition et de montage. Selon Pierre Lévy, philosophe français spécialisé dans l’étude de l’impact d’Internet sur la société, ‹ le numérique est l’absolu du montage, le montage portant sur les plus infimes fragments du message, une disponibilité indéfinie et sans cesse réouverte à la combinaison, au mixage, au réordonnancement des signes. ›[^127]
Mais face au développement de ces logiciels, mettant à notre disposition toujours plus d’effets et de presets, il est bon de se rappeler comme nous venons de la faire, des principes de base liés à la coexistence, la confrontation et la succession dans l’espace et dans le temps de deux éléments ou plus, et ce, quelle que soit la nature du contenu (audio, vidéo ou visuel).

Cette digression interdisciplinaire nous a permis de nous rendre compte qu’il existe des mécaniques communes à toute forme d’assemblage. Mais comme nous l’évoquions dans le premier chapitre à propos des pratiques appropriatoires du curateur-artiste et de l’artiste contemporain, il existe deux “degrés” de montage qu’il convient d’identifier. L’artiste montant son projet, le curateur montant son exposition : tous deux rencontrent certaines problématiques communes, mais à des échelles différentes. Et pour reprendre la distinction opérée par Lev Manovich, deux grandes tendances esthétiques s’opposent en la matière[^128] :
– l’esthétique du montage, qui ‹ cherche à créer une dissonance visuelle, stylistique, sémantique et émotionnelle entre les différents éléments. ›
– l’esthétique de la continuité, qui ‹ cherche, au contraire, à les fusionner en un tout sans raccords, en un gestalt unique › ;

Du rôle d’editor, notre créateur passe alors à celui d’assembleur/monteur. Il s’agit dès lors de créer un véritable scénario à partir des contenus sélectionnés, de les faire dialoguer, d’établir entre eux des liens, des passages, des connections. Pour paraphraser le réalisateur américain et maître du found footage[^129] Bruce Conner (1933–2008), nous dirons donc que ce stade du processus consiste à travailler avec un corpus de contenus, de les assembler, et, peut-être, de leur faire produire des choses absentes de l’intention de départ.[^130]
En fonction du type de contenu manipulé, des supports et des outils d’expression choisis, un travail de design peut alors être nécessaire, afin de trouver les solutions formelles et stylistiques les plus adéquates à la traduction et la compréhension de ce tissu complexe de relations ainsi scénarisées.

Je conclurai cette réflexion autour des notions d’assemblage et de montage en effectuant une nouvelle digression à propos du rapport particulier qu’entretient le créateur-programmeur avec le contenu qu’il manipule. Comme l’explique parfaitement Samuel Bianchini (artiste et enseignant-chercheur français), au travers d’un dispositif interactif, ‹ l’auteur “virtualise” le montage ›, puis le spectateur l’actualise :

‹ Il ne l’accomplit pas, mais en fixe les règles, la syntaxe et les procédures : il définit un programme. […] Le montage est suspendu à mi-parcours, il est potentiel et s’accomplira lors de la phase d’agencement déléguée au spectateur. ›[^131]

‹ L’auteur-programmeur propose des hypothèses de situation en créant des modalités de rapport à des images (dispositif). Si l’activité du DJ est fortement liée à un temps présent focalisé sur l’actualité du mix et l’actualisation des morceaux qu’il emploie, le programmeur agit en amont, il configure et reconfigure pour tenter de prévoir des possibles, il est avant tout dans le potentiel. ›[^132]

Comme le souligne le statut particulier de l’œuvre interactive, les choix du/des dispositif(s) de monstration ainsi que du/des mode(s) de diffusion du projet sont loin d’être sans importance et constituent l’étape suivante de notre processus.


#### 5. Montrer, diffuser
Il s’agit à présent de déterminer quelles seront les conditions d’existence du projet. Où et comment sera-t-il montré ? Dans quelles circonstances ? Qui y aura accès ? Pendant combien de temps ? Autant de questions auxquelles les créateurs ne sont toujours habitués à répondre, mais qui constituent pourtant une partie non négligeable de la vie d’un projet.

Nous abordons ici un point important qui est la notion de dispositif. Selon Giorgio Agamben, philosophe italien spécialiste de la pensée de Walter Benjamin, de Heidegger, de Carl Schmitt et d’Aby Warburg, un dispositif désigne ‹ tout ce qui a, d’une manière ou d’une autre, la capacité de capturer, d’orienter, de déterminer, d’intercepter, de modeler, de contrôler et d’assurer les gestes, les conduites, les opinions et les discours des êtres vivants. ›[^133] Appliquée à l’idée de “dispositif de monstration”, cette définition nous permet de mieux cerner les enjeux de cette étape dans notre contexte.
Quel(s) dispositif(s) de monstration sera/seront le(s) plus adapté(s) au projet ? Pour le savoir, il faut déterminer quel rapport souhaitons-nous que le spectateur entretienne avec lui, quelle expérience voulons-nous qu’il vive.

Pour reprendre l’exemple d’un mix réalisé par un DJ, de nombreuses possibilités sont envisageables. Il peut en effet soit être produit en live dans un lieu donné, face à un public ou non, et éventuellement retransmis en direct sous forme vidéo[^134] ou uniquement audio ; soit être enregistré et diffusé sur le web, à la radio, sur une webradio, ou hébergé sur une plate-forme de lecture et de partage en ligne[^135], qui proposera ou non à l’auditeur de pouvoir le télécharger sur son ordinateur pour l’écouter hors-ligne. Il peut également être édité (auto-édité ou via un label) “en physique” sous forme de vinyle, de CD ou de cassette, pour être ensuite distribué sur le web ou en magasins.
Au travers de cette longue liste de solutions en terme de monstration et de diffusion d’un mix audio – solutions pouvant, qui plus est, être cumulées – on voit bien comment un même projet au départ peut prendre vie et exister de multiples façons, chacune possédant ses propres qualités et proposant à l’auditeur une expérience différente.

Concernant l’accès au projet, deux approches sont donc à considérer : l’accès au sein d’un lieu physique (boutique, galerie, festival, exposition, soirée, événement, etc.) ou l’accès via le web (plates-formes, site dédié, etc.). Là où la première mettra l’accent sur l’expérience sensorielle du spectateur, la seconde permettra en revanche un accès au projet plus large, à la fois quantitativement et géographiquement. De plus, chacune d’elles proposera une expérience sociale différente, physique et limitée dans le temps d’une part, connectée et étalée dans le temps de l’autre.
Et là encore, les principes d’interactivité posent depuis quelques années de nouvelles questions concernant la participation du spectateur aux dispositifs de monstration : intégrations des réseaux sociaux, expositions virtuelles, clips et documentaires interactifs, éditions numériques, narration transmédia, réalité augmentée… de nouveaux dispositifs hybrides se développent grâce au possibilités offertes par les technologies du web et du numérique. L’objectif premier de ces différents croisements de supports et de formats reste le plus souvent de proposer au spectateur / utilisateur de faire l’expérience de nouvelles façons de consommer du contenu, artistique ou non. Cela étant, l’attrait que constitue la nouveauté de ces dispositifs a parfois tendance à délaisser le fond des projets et le sens donné aux interactions. Mais c’est là un autre débat.

#### 6. Restituer, archiver
En dernier lieu, nous allons nous intéresser brièvement aux questions relatives à la restitution d’un projet et à son archivage. Un projet diffusé sur le web étant le plus souvent accessible de façon indéterminée – quelques exceptions dérogent cependant à ce constat général[^136] – ces questions se posent essentiellement lorsque que le dispositif de monstration choisi induit la diffusion dans un espace physique, telle une exposition ou un toute autre forme d’événement.
Il s’agit alors de garder une trace du projet afin de pouvoir en rendre compte a posteriori. Cela passera la plupart du temps par un ou plusieurs dispositifs de captation (audio, photo, vidéo) qui généreront de nouveau du contenu. Celui-ci pourra alors soit être exploité à l’état brut et ainsi constituer une archive du projet, soit constituer à son tour un matériau de travail, dans le cadre du même projet, ou dans un nouveau contexte.

Les formes de restitution d’un projet les plus courantes sont le film documentaire[^137] et l’édition[^138] (catalogue, livre, vinyle, etc.). Lors de leur réalisation, se reposeront alors les mêmes questions abordées dans les parties précédentes concernant l’organisation, l’editing, l’assemblage du contenu et la diffusion du résultat.

Mise en ligne et bien référencée (titre, tags, chaînes et sites officiels, etc.), la restitution ou l’archive d’un projet permettra de nouveau à tout internaute de la trouver, la consulter, et éventuellement se l’approprier, bouclant ainsi la boucle.

Si dans ces deux dernières parties consacrées à la monstration et la restitution d’un projet, nous nous sommes légèrement éloignés des questions spécifiques à la pratique du mix – d’où leur longueur moindre – il m’a tout de même semblé intéressant d’aborder ces problématiques plus générales afin de souligner l’importance des choix inhérents à ces étapes dans la vie de tout projet, relevant ou non de la pratique du mix.
Riches de cette analyse, nous allons nous refocaliser dans le chapitre suivant sur la notion de mix, le statut et les enjeux propres à cette pratique, ainsi que sur la façon dont celle-ci induit une attitude symptomatique de notre société vis-à-vis du monde culturel qui nous entoure.

[^92]: Voir la page dédiée à ce sujet sur le site du WC3 http://www.w3.org/2001/sw/
[^93]: http://fr.wikipedia.org/wiki/Web_sémantique
[^94]: http://fr.wikipedia.org/wiki/Entrées-sorties
[^95]: http://fr.wikipedia.org/wiki/Moteur_de_recherche
[^96]: Le poids d’un terme reflète à la fois la probabilité d’apparition du mot dans un document et le “pouvoir discriminant de ce mot” dans une langue, conformément au principe de la formule TF-IDF (Term Frequency-Inverse Document Frequency) http://fr.wikipedia.org/wiki/TF-IDF
[^97]: Pour l’anecdote, l’inventeur de ce système de pages n’est autre que Larry Page, co-fondateur et actuel PDG de Google.
[^98]: http://fr.wikipedia.org/wiki/Sérendipité#D.C3.A9finitions_diverses
[^99]: Jean-Marie Durand, « La sérendipité : l’art de trouver ce que l’on ne cherche pas », Les Inrocks, 14 juillet 2011 [en ligne] http://www.lesinrocks.com/2011/07/14/medias/internet/la-serendipite-lart-de-trouver-ce-quon-ne-cherche-pas-1112714/ [consulté le 20 décembre 2013]
[^100]: *Ibid.*
[^101]: http://fr.wikipedia.org/wiki/Folksonomie
[^102]: Voir à ce sujet Georges Perec, « Notes concernant les objets qui sont sur ma table de travail », in  Penser/Classer, Hachette, coll. « Littérature », 1985, p. 22 http://www.mediatheques.scientipole.fr/sites/default/files/fichiers_attaches/dossiers/perec_tabletravail.pdf
[^103]: Georges Perec, *op. cit.*
[^104]: Michel Foucault, *Les Mots et les choses*, Paris, Gallimard, coll. « Tel », [^1966:] 2010.
[^105]: Gérard Régimbeau, « Classer, c’est penser », Hermès, La Revue, 2013/2 n° 66, p. 16-17. 
[^106]: http://fr.wiktionary.org/wiki/trier
[^107]: http://fr.wikipedia.org/wiki/Catégorisation
[^108]: Richard Landwein, « Catégorisaitons cognitives et jugement de typicalité en comportement du consommateur », in Recherche et Applications en Marketing, vol 10, n°2, 1995. http://le-marketing-pour-tous.6mablog.com/public/Categories_cognitives_et_jugement_de_typicalite_en_comportement_du_consommateur.pdf [p. 8]
[^109]: La norme XMP à largement remplacé la structure des fichiers IIM (Information Interchange Model) conçu par l’IPTC (Internationnal Press Telecommunication Council) au début des années 90, mais en a conservé les attributs de métadonnées IPTC Core.
[^110]: Pour plus de détails, voir le site officiel http://id3.org/
[^111]: Voir par exemple http://labeur.tumblr.com/
[^112]: La page Wikipédia au sujet de l’editing n’existe pas en français ! http://en.wikipedia.org/wiki/Editing
[^113]: Mamishev, Alexander, Williams, Sean, Technical Writing for Teams: The STREAM Tools Handbook, Institute of Electrical and Electronics Engineers, John Wiley & Sons. Inc., Hoboken, 2009, p.128
[^114]: http://fr.wikipedia.org/wiki/Liste_de_lecture
[^115]: Jean-Yves Leloup, *op. cit.*, p. 111
[^116]: Lev Manovich, *op. cit.*, p. 58
[^117]: Atténuer ou accentuer une ou plusieurs bandes de fréquences composant un signal audio.
http://fr.wikipedia.org/wiki/Égaliseur
[^118]: L’art de créer de la musique grâce aux platines et disques vinyles http://fr.wikipedia.org/wiki/Turntablism
[^119]: http://fr.wikipedia.org/wiki/Effet_Koulechov
[^120]: Jean-Nicolas Berniche, « Miscellanée #15 : l’effet K », Grand Écart, 3 novembre 2013 [en ligne] http://www.grand-ecart.fr/miscellanees/effet-koulechov-mosjoukine-technique-montage/ [consulté le 23 décembre 2013]
[^121]: Scott McCloud, *L’Art Invisible*, Paris, Delcourt, Contrebande, 2007 (1993), pp. 78–82
[^122]: *Ibid.*, p. 81
[^123]: http://www.bernardwerber.com/unpeuplus/innerview/pages/Amour.htm
[^124]: http://classes.yale.edu/film-analysis/htmfiles/editing.htm
[^125]: Lorsque cet effet est utilisé sans élément avant, on appelle cela un fade-in ; et à l’inverse, sans élément après, il s’agira d’un fade-out. En cinéma, on parle en français d’entrée (ou de sortie) au noir (ou au blanc).
[^126]: Jean Douchet, « Les fantômes de la surimpression », Cahiers du cinéma, no 465,‎ mars 1993, pp. 50–52
[^127]: Pierre Lévy, L’Intelligence collective – Pour une anthropologie du cyberspace, Paris, La Découverte, coll. « Sciences et société », 1995, pp. 57–58
[^128]: Lev Manovich, « Digital Compositing, Montage and Anti-Montage », 1999
[^129]: Le found footage est le terme anglais (littéralement « métrage trouvé ») désignant la récupération de pellicules impressionnées dans le but d’enregistrer un autre film. http://fr.wikipedia.org/wiki/Found_footage
[^130]: Bruce Conner, « Un film », Monter/Sampler: l’échantillonnage généralisé, Yann Beauvaix et Jean-Michel Bouhours (sous la dir. de), Paris, Éditions du Centre Pompidou, 2000, p. 107
[^131]: Samuel Bianchini, « Une opération partagée – le montage confronté aux technologies de l’interactivité », Monter/Sampler: l’échantillonnage généralisé, Yann Beauvaix et Jean-Michel Bouhours (sous la dir. de), Paris, Éditions du Centre Pompidou, 2000, p. 110
[^132]: *Ibid.*, p. 112
[^133]: Giorgio Agamben, Qu’est-ce qu’un dispositif ?, Paris, Éditions Payot et Rivages, coll. Rivages poche / Petite Bibliothèque, 2007 (2006), quatrième de couverture.
[^134]: Voir par exemple les soirées Boiler Room http://boilerroom.tv/
[^135]: Mixcloud, SoundCloud, Mixcrate ou encore Mix.dj pour ne citer que les plus populaires.
[^136]: Voir par exemple le projet Gallery of Lost Art organisé par le Tate Museum et réalisé par le studio ISO en 2013 http://galleryoflostart.com/
[^137]: Histoire de garder le même exemple, voir la page regroupant les vidéos réalisées autour du projet http://vimeo.com/album/2152181
[^138]: Sans oublier le livre qui va avec !
Jennifer Mundy, Lost Art: Missing Artworks of the Twentieth Century, Londres, Tate Publishing, 2013 http://shop.tate.org.uk/modern-and-contemporary-art/lost-art-missing-artworks-of-the-twentieth-century/invt/13788

###### tags: `Mixing Culture`